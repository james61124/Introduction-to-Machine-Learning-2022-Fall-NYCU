{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HO05iezPUX4w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2tlripadDwG"
      },
      "source": [
        "part1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "ZxaaGcbudFd4",
        "outputId": "932c1b7e-eb71-4301-99a7-135aab9cfbfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gini of data is  0.4628099173553719\n",
            "Entropy of data is  0.9456603046006401\n",
            "(1200, 21)\n",
            "(300, 21)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>battery_power</th>\n",
              "      <th>blue</th>\n",
              "      <th>clock_speed</th>\n",
              "      <th>dual_sim</th>\n",
              "      <th>fc</th>\n",
              "      <th>four_g</th>\n",
              "      <th>int_memory</th>\n",
              "      <th>m_dep</th>\n",
              "      <th>mobile_wt</th>\n",
              "      <th>n_cores</th>\n",
              "      <th>...</th>\n",
              "      <th>px_height</th>\n",
              "      <th>px_width</th>\n",
              "      <th>ram</th>\n",
              "      <th>sc_h</th>\n",
              "      <th>sc_w</th>\n",
              "      <th>talk_time</th>\n",
              "      <th>three_g</th>\n",
              "      <th>touch_screen</th>\n",
              "      <th>wifi</th>\n",
              "      <th>price_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1583</td>\n",
              "      <td>1</td>\n",
              "      <td>2.1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0.7</td>\n",
              "      <td>148</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>942</td>\n",
              "      <td>1651</td>\n",
              "      <td>1704</td>\n",
              "      <td>17</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>745</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0.8</td>\n",
              "      <td>102</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>89</td>\n",
              "      <td>1538</td>\n",
              "      <td>2459</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>832</td>\n",
              "      <td>0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>0.7</td>\n",
              "      <td>103</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>125</td>\n",
              "      <td>1504</td>\n",
              "      <td>1799</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1175</td>\n",
              "      <td>1</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>0.3</td>\n",
              "      <td>164</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>873</td>\n",
              "      <td>1394</td>\n",
              "      <td>1944</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>695</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>0.6</td>\n",
              "      <td>196</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1649</td>\n",
              "      <td>1829</td>\n",
              "      <td>2855</td>\n",
              "      <td>16</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
              "0           1583     1          2.1         1  11       0          14    0.7   \n",
              "1            745     1          0.6         1   5       0          35    0.8   \n",
              "2            832     0          0.7         1   2       1          39    0.7   \n",
              "3           1175     1          1.3         0   2       0          19    0.3   \n",
              "4            695     0          0.5         0  18       1          12    0.6   \n",
              "\n",
              "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
              "0        148        7  ...        942      1651  1704    17    13          2   \n",
              "1        102        8  ...         89      1538  2459    14     1         16   \n",
              "2        103        4  ...        125      1504  1799     5     2         11   \n",
              "3        164        7  ...        873      1394  1944     9     4          9   \n",
              "4        196        2  ...       1649      1829  2855    16    13          7   \n",
              "\n",
              "   three_g  touch_screen  wifi  price_range  \n",
              "0        1             0     1            1  \n",
              "1        1             1     0            0  \n",
              "2        1             0     1            0  \n",
              "3        1             1     0            0  \n",
              "4        1             1     1            1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def gini(sequence):\n",
        "    \n",
        "    counts = {}\n",
        "    for row in sequence:\n",
        "        label = row\n",
        "        if label not in counts:\n",
        "            counts[label] = 0\n",
        "        counts[label] += 1\n",
        "    impurity = 1\n",
        "    for lbl in counts:\n",
        "        prob_of_lbl = counts[lbl] / float(len(sequence))\n",
        "        impurity -= prob_of_lbl**2\n",
        "\n",
        "    return impurity\n",
        "\n",
        "\n",
        "def entropy(sequence):\n",
        "    counts = {}\n",
        "    for row in sequence:\n",
        "        label = row\n",
        "        if label not in counts:\n",
        "            counts[label] = 0\n",
        "        counts[label] += 1\n",
        "    impurity = 0\n",
        "    for lbl in counts:\n",
        "        prob_of_lbl = counts[lbl] / float(len(sequence))\n",
        "        impurity += - prob_of_lbl* np.log2(prob_of_lbl)\n",
        "    return impurity\n",
        "\n",
        "data = np.array([1,2,1,1,1,1,2,2,1,1,2])\n",
        "print(\"Gini of data is \", gini(data))\n",
        "print(\"Entropy of data is \", entropy(data))\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "val_df = pd.read_csv('val.csv')\n",
        "print(train_df.shape)\n",
        "print(val_df.shape)\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tGBgqskdJS2"
      },
      "source": [
        "part2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxU8cweodIzz",
        "outputId": "2f5a39db-f63c-4751-80b9-65f80edf899c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.92\n",
            "0.93\n",
            "0.92\n",
            "0.9333333333333333\n"
          ]
        }
      ],
      "source": [
        "def is_numeric(value):\n",
        "    return isinstance(value, int) or isinstance(value, float)\n",
        "\n",
        "class Question:\n",
        "    '''\n",
        "    store the question of each node\n",
        "    '''\n",
        "    def __init__(self, column, value):\n",
        "        self.column = column\n",
        "        self.value = value\n",
        "\n",
        "    def match(self, example):\n",
        "        # Compare the feature value in an example to the feature value in this question.\n",
        "        val = example[self.column]\n",
        "        if is_numeric(val):\n",
        "            return val >= self.value\n",
        "        else:\n",
        "            return val == self.value\n",
        "\n",
        "def class_counts(rows): \n",
        "    counts = {}\n",
        "    for row in rows:\n",
        "        label = row[-1]\n",
        "        if label not in counts:\n",
        "            counts[label] = 0\n",
        "        counts[label] += 1\n",
        "    return counts\n",
        "\n",
        "def partition(rows, question): # divide the dataset into two part based on the question\n",
        "    true_rows, false_rows = [], []\n",
        "    for row in rows:\n",
        "        if question.match(row):\n",
        "            true_rows.append(row)\n",
        "        else:\n",
        "            false_rows.append(row)\n",
        "    true_rows = np.array(true_rows)\n",
        "    false_rows = np.array(false_rows)\n",
        "    return true_rows, false_rows\n",
        "\n",
        "\n",
        "def info_gain(left, right, current_uncertainty, criterion): # calculate the information gain\n",
        "    p = float(len(left)) / (len(left) + len(right))\n",
        "    return current_uncertainty - p * eval(criterion+\"(left[:,-1])\") - (1 - p) * eval(criterion+\"(right[:,-1])\") \n",
        "\n",
        "def find_best_split(rows, criterion, is_boostrap): # find the best question for the partition\n",
        "    best_gain = 0 \n",
        "    best_question = None \n",
        "    current_uncertainty = eval(criterion+\"(rows[:,-1])\")\n",
        "    n_features = len(rows[0]) - 1\n",
        "    if is_boostrap == 0:\n",
        "        for col in range(n_features):  \n",
        "            values = set([row[col] for row in rows]) \n",
        "            for val in values:\n",
        "                question = Question(col, val)\n",
        "                true_rows, false_rows = partition(rows, question)\n",
        "                if len(true_rows) == 0 or len(false_rows) == 0:\n",
        "                    continue\n",
        "                gain = info_gain(true_rows, false_rows, current_uncertainty, criterion)\n",
        "                if gain > best_gain:\n",
        "                    best_gain, best_question = gain, question\n",
        "    else:\n",
        "        feature_index = random.sample(range(len(rows[0])-1), int(is_boostrap))\n",
        "        #print(feature_index)\n",
        "        for col in range(n_features): \n",
        "            if col in feature_index: \n",
        "                values = set([row[col] for row in rows]) \n",
        "                for val in values:\n",
        "                    question = Question(col, val)\n",
        "                    true_rows, false_rows = partition(rows, question)\n",
        "                    if len(true_rows) == 0 or len(false_rows) == 0:\n",
        "                        continue\n",
        "                    gain = info_gain(true_rows, false_rows, current_uncertainty, criterion)\n",
        "                    if gain >= best_gain:\n",
        "                        best_gain, best_question = gain, question\n",
        "\n",
        "    return best_gain, best_question\n",
        "\n",
        "class Leaf: # the end of the tree\n",
        "    def __init__(self, rows):\n",
        "        inverse = [(value, key) for key, value in class_counts(rows).items()]\n",
        "        self.predictions = max(inverse)[1]\n",
        "    \n",
        "class Decision_Node: # tree node\n",
        "    def __init__(self,\n",
        "                 question,\n",
        "                 true_branch,\n",
        "                 false_branch,\n",
        "                 len_true_branch,\n",
        "                 len_false_branch):\n",
        "        self.question = question\n",
        "        self.true_branch = true_branch\n",
        "        self.false_branch = false_branch\n",
        "        self.len_true_branch = len_true_branch\n",
        "        self.len_false_branch = len_false_branch\n",
        "\n",
        "def classify(row, node):\n",
        "    if isinstance(node, Leaf):\n",
        "        return node.predictions\n",
        "    if node.question.match(row):\n",
        "        return classify(row, node.true_branch)\n",
        "    else:\n",
        "        return classify(row, node.false_branch)\n",
        "\n",
        "features_counting = np.zeros(20) #part3\n",
        "gini_index_adaboost = 0 #part4\n",
        "class DecisionTree(): # aiming to build the decision tree\n",
        "    def __init__(self, criterion='gini', max_depth=None, gini_index_adaboost=0, boostrap=False, max_features=0):\n",
        "        self.criterion = criterion\n",
        "        self.max_depth = max_depth\n",
        "        self.gini_index_adaboost = gini_index_adaboost\n",
        "        self.false_rows = []\n",
        "        self.boostrap = boostrap\n",
        "        self.max_features = max_features\n",
        "        \n",
        " \n",
        "    def build_tree(self, x_data, y_data, level): # build the decision tree\n",
        "        x_data = np.array(x_data)\n",
        "        y_data = np.array(y_data)\n",
        "        y_data = np.reshape(y_data, (len(y_data), 1))\n",
        "        x_data = np.append(x_data, y_data, axis=1)\n",
        "        data = x_data\n",
        "\n",
        "        if self.boostrap == False:\n",
        "            gain, question = find_best_split(data, self.criterion, 0)\n",
        "        else:\n",
        "            gain, question = find_best_split(data, self.criterion, self.max_features)\n",
        "    \n",
        "        if gain == 0 or level == self.max_depth:\n",
        "            return Leaf(data)\n",
        "        true_rows, false_rows = partition(data, question)\n",
        "        self.gini_index_adaboost = info_gain(true_rows, false_rows, 1, 'gini')\n",
        "        self.false_rows = false_rows\n",
        "        #print(question.column, question.value, len(true_rows), len(false_rows))\n",
        "        features_counting[question.column] = features_counting[question.column] + 1\n",
        "        true_rows_x = true_rows[:,0:(len(true_rows[0])-1)]\n",
        "        true_rows_y = true_rows[:,-1]\n",
        "        false_rows_x = false_rows[:,0:(len(false_rows[0])-1)]\n",
        "        false_rows_y = false_rows[:,-1]\n",
        "\n",
        "        level = level + 1\n",
        "        true_branch = self.build_tree(true_rows_x, true_rows_y, level)\n",
        "        false_branch = self.build_tree(false_rows_x, false_rows_y, level)\n",
        "        #self.tree = Decision_Node(question, true_branch, false_branch, len(true_rows), len(false_rows))\n",
        "        return Decision_Node(question, true_branch, false_branch, len(true_rows), len(false_rows))\n",
        "    \n",
        "    def fit(self, x_data, y_data): \n",
        "        self.tree = self.build_tree(x_data, y_data, 0)\n",
        "\n",
        "    def predict(self, x_test): # return the predicted y based on the decision tree\n",
        "        y_pred = []\n",
        "        for row in x_test:\n",
        "            y_pred.append(classify(row, self.tree))\n",
        "        y_pred = np.array(y_pred)\n",
        "        return y_pred\n",
        "\n",
        "clf_depth3 = DecisionTree(criterion='gini', max_depth=3)\n",
        "train_df_x = np.array(train_df.values)[:,0:(len(train_df.values[0])-1)]\n",
        "train_df_y = np.array(train_df.values)[:,-1]\n",
        "val_df_x = np.array(val_df.values)[:,0:(len(val_df.values[0])-1)]\n",
        "val_df_y = np.array(val_df.values)[:,-1]\n",
        "clf_depth3_tree = clf_depth3.fit(train_df_x, train_df_y)\n",
        "y_pred = clf_depth3.predict(val_df_x)\n",
        "print(accuracy_score(val_df_y, y_pred))\n",
        "\n",
        "clf_depth10 = DecisionTree(criterion='gini', max_depth=10)\n",
        "train_df_x = np.array(train_df.values)[:,0:(len(train_df.values[0])-1)]\n",
        "train_df_y = np.array(train_df.values)[:,-1]\n",
        "val_df_x = np.array(val_df.values)[:,0:(len(val_df.values[0])-1)]\n",
        "val_df_y = np.array(val_df.values)[:,-1]\n",
        "clf_depth10_tree = clf_depth10.fit(train_df_x, train_df_y)\n",
        "y_pred = clf_depth10.predict(val_df_x)\n",
        "print(accuracy_score(val_df_y, y_pred))\n",
        "\n",
        "clf_gini = DecisionTree(criterion='gini', max_depth=3)\n",
        "train_df_x = np.array(train_df.values)[:,0:(len(train_df.values[0])-1)]\n",
        "train_df_y = np.array(train_df.values)[:,-1]\n",
        "val_df_x = np.array(val_df.values)[:,0:(len(val_df.values[0])-1)]\n",
        "val_df_y = np.array(val_df.values)[:,-1]\n",
        "clf_gini_tree = clf_gini.fit(train_df_x, train_df_y)\n",
        "y_pred = clf_gini.predict(val_df_x)\n",
        "print(accuracy_score(val_df_y, y_pred))\n",
        "\n",
        "clf_entropy = DecisionTree(criterion='entropy', max_depth=3)\n",
        "train_df_x = np.array(train_df.values)[:,0:(len(train_df.values[0])-1)]\n",
        "train_df_y = np.array(train_df.values)[:,-1]\n",
        "val_df_x = np.array(val_df.values)[:,0:(len(val_df.values[0])-1)]\n",
        "val_df_y = np.array(val_df.values)[:,-1]\n",
        "clf_entropy_tree = clf_entropy.fit(train_df_x, train_df_y)\n",
        "y_pred = clf_entropy.predict(val_df_x)\n",
        "print(accuracy_score(val_df_y, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLOFDpyydPk_"
      },
      "source": [
        "part3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "lovOwyS1dQ14",
        "outputId": "8d4594aa-5d21-4114-f630-db88b62c2a98"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "label = ['battery_power','blue','clock_speed','dual_sim','fc','four_g','int_memory','m_dep','mobile_wt','n_cores','pc','px_height','px_width','ram','sc_h','sc_w','talk_time','three_g','touch_screen','wifi']\n",
        "new_h = []\n",
        "new_label = []\n",
        "new_features_counting = []\n",
        "count = 1\n",
        "for i in range(20):\n",
        "    if features_counting[i] != 0:\n",
        "        new_h.append(count)\n",
        "        new_label.append(label[i])\n",
        "        new_features_counting.append(features_counting[i])\n",
        "        count = count + 1\n",
        "new_h = np.array(new_h)\n",
        "new_label = np.array(new_label)\n",
        "new_features_counting = np.array(new_features_counting)\n",
        "plt.barh(new_h,new_features_counting,tick_label=new_label,height=0.2)  # 改成 barh\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu3dbi8jdUmi"
      },
      "source": [
        "part4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YvN21RgdWAO",
        "outputId": "a61f08f3-a78b-44b7-e943-4fac55a37bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9266666666666666\n",
            "0.9733333333333334\n"
          ]
        }
      ],
      "source": [
        "class AdaBoost:\n",
        "    def __init__(self, n_estimators, max_depth=1):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def cal_amount_of_say(self, total_error): # calculate amount_of_say\n",
        "        return (1/2) * np.log((1-total_error)/total_error)\n",
        "\n",
        "    def fit(self, x_data, y_data):\n",
        "        x_data = np.array(x_data)\n",
        "        y_data = np.array(y_data)\n",
        "        y_data = np.reshape(y_data, (len(y_data), 1))\n",
        "        x_data = np.append(x_data, y_data, axis=1)\n",
        "        #y_data = np.reshape(y_data, len(y_data))\n",
        "        data = x_data\n",
        "\n",
        "        n_column = len(data[0])\n",
        "        n_row = len(data)\n",
        "\n",
        "        self.clfs = []\n",
        "        self.amount_of_say = []\n",
        "\n",
        "        w = np.full(n_row, (1 / n_row))\n",
        "        update_data = data\n",
        "\n",
        "        for j in range(self.n_estimators):\n",
        "            amount_of_say = 0\n",
        "\n",
        "            clf = DecisionTree(criterion='gini', max_depth=self.max_depth)\n",
        "            clf.fit(update_data[:,0:(len(update_data[0])-1)], update_data[:,-1])\n",
        "            clf_tree = clf.tree\n",
        "            total_error = 0\n",
        "            for i in range(len(data)):\n",
        "                if classify(data[i],clf_tree) != data[i][-1]:\n",
        "                    total_error = total_error + w[i]\n",
        "            \n",
        "            amount_of_say = self.cal_amount_of_say(total_error)\n",
        "            self.amount_of_say.append(amount_of_say)\n",
        "            self.clfs.append(clf_tree)\n",
        "\n",
        "            for i in range(n_row):\n",
        "                if classify(data[i],clf_tree) == data[i][-1]:\n",
        "                    w[i] = w[i] * np.exp(-amount_of_say)\n",
        "                else:\n",
        "                    w[i] = w[i] * np.exp(amount_of_say)\n",
        "            w = np.array(w)\n",
        "            w = w / w.sum(axis=0,keepdims=1)\n",
        "            new_data = np.empty(shape=(n_row,n_column))\n",
        "            new_data.fill(0)\n",
        "            index = []\n",
        "            for i in range(n_row):\n",
        "                index.append(i)\n",
        "            w = w.tolist()\n",
        "            index = np.random.choice(data.shape[0], data.shape[0], replace=True, p=w)\n",
        "            index = index.tolist()\n",
        "            update_data = np.empty(shape=(data.shape[0],data.shape[1]))\n",
        "            update_data.fill(0)\n",
        "            for i in range(data.shape[0]):\n",
        "                update_data[i] = data[index[i]]\n",
        "\n",
        "    def predict(self, x_test):\n",
        "        answer = []\n",
        "        for i in range(len(x_test)):\n",
        "            amount_of_say_0 = 0\n",
        "            amount_of_say_1 = 0\n",
        "            j = 0\n",
        "            for clf in self.clfs:\n",
        "                category = classify(x_test[i],clf)\n",
        "                if category == 0:\n",
        "                    amount_of_say_0 += self.amount_of_say[j]\n",
        "                else:\n",
        "                    amount_of_say_1 += self.amount_of_say[j]\n",
        "                j = j + 1\n",
        "            if amount_of_say_0 > amount_of_say_1:\n",
        "                answer.append(0)\n",
        "            else:\n",
        "                answer.append(1)\n",
        "        return answer\n",
        "\n",
        "\n",
        "clf_estimate10 = AdaBoost(10)\n",
        "train_df_x = np.array(train_df.values)[:,0:(len(train_df.values[0])-1)]\n",
        "train_df_y = np.array(train_df.values)[:,-1]\n",
        "val_df_x = np.array(val_df.values)[:,0:(len(val_df.values[0])-1)]\n",
        "val_df_y = np.array(val_df.values)[:,-1]\n",
        "clf_estimate10_tree = clf_estimate10.fit(train_df_x, train_df_y)\n",
        "y_pred = clf_estimate10.predict(val_df_x)\n",
        "print(accuracy_score(val_df_y, y_pred))\n",
        "\n",
        "clf_estimate100 = AdaBoost(100)\n",
        "train_df_x = np.array(train_df.values)[:,0:(len(train_df.values[0])-1)]\n",
        "train_df_y = np.array(train_df.values)[:,-1]\n",
        "val_df_x = np.array(val_df.values)[:,0:(len(val_df.values[0])-1)]\n",
        "val_df_y = np.array(val_df.values)[:,-1]\n",
        "clf_estimate100_tree = clf_estimate100.fit(train_df_x, train_df_y)\n",
        "y_pred = clf_estimate100.predict(val_df_x)\n",
        "print(accuracy_score(val_df_y, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ll0L9NzdYzW"
      },
      "source": [
        "part5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV7ssJGcdaAm",
        "outputId": "90f14294-8cfd-44f1-c4df-b0bfad71d777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.92\n",
            "0.9466666666666667\n",
            "0.9366666666666666\n",
            "0.9566666666666667\n"
          ]
        }
      ],
      "source": [
        "class RandomForest():\n",
        "    def __init__(self, n_estimators, max_features, boostrap=True, criterion='gini', max_depth=None):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_features = max_features\n",
        "        self.boostrap = boostrap\n",
        "        self.criterion = criterion\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def fit(self, x_data, y_data):\n",
        "        x_data = np.array(x_data)\n",
        "        y_data = np.array(y_data)\n",
        "        y_data = np.reshape(y_data, (len(y_data), 1))\n",
        "        x_data = np.append(x_data, y_data, axis=1)\n",
        "        #y_data = np.reshape(y_data, len(y_data))\n",
        "        data = x_data\n",
        "        self.clfs = []\n",
        "        \n",
        "        for i in range(self.n_estimators):\n",
        "            #print(i)\n",
        "            data_random = []\n",
        "            for j in range(len(data)):\n",
        "                index = random.randint(0, len(data)-1)\n",
        "                data_random = np.array(data_random)\n",
        "                data_random = np.append(data_random, data[index])\n",
        "            data_random = np.reshape(data_random, (len(data),len(data[0])))\n",
        "\n",
        "            clf = DecisionTree(criterion='gini', max_depth=None, boostrap=True, max_features=self.max_features)\n",
        "            clf.fit(data_random[:,0:(len(data_random[0])-1)], data_random[:,-1])\n",
        "            clf_tree = clf.tree\n",
        "            self.clfs.append(clf_tree)\n",
        "            \n",
        "\n",
        "    def predict(self, x_test):\n",
        "        answer = []\n",
        "        for i in range(len(x_test)):\n",
        "            class_0 = 0\n",
        "            class_1 = 0\n",
        "            for clf in self.clfs:\n",
        "                #print(data[i])\n",
        "                category = classify(x_test[i],clf)\n",
        "                if category == 0:\n",
        "                    class_0 += 1\n",
        "                else:\n",
        "                    class_1 += 1\n",
        "            if class_0 < class_1:\n",
        "                answer.append(1)\n",
        "            else:\n",
        "                answer.append(0)\n",
        "        return answer\n",
        "\n",
        "train_df_x = np.array(train_df.values)[:,0:(len(train_df.values[0])-1)]\n",
        "train_df_y = np.array(train_df.values)[:,-1]\n",
        "val_df_x = np.array(val_df.values)[:,0:(len(val_df.values[0])-1)]\n",
        "val_df_y = np.array(val_df.values)[:,-1]\n",
        "\n",
        "\n",
        "clf_10tree = RandomForest(n_estimators=10, max_features=np.sqrt(len(train_df_x[0])))\n",
        "clf_10tree_tree = clf_10tree.fit(train_df_x, train_df_y)\n",
        "y_pred = clf_10tree.predict(val_df_x)\n",
        "print(accuracy_score(val_df_y, y_pred))\n",
        "clf_100tree = RandomForest(n_estimators=100, max_features=np.sqrt(len(train_df_x[0])))\n",
        "clf_100tree_tree = clf_100tree.fit(train_df_x, train_df_y)\n",
        "y_pred = clf_100tree.predict(val_df_x)\n",
        "print(accuracy_score(val_df_y, y_pred))\n",
        "clf_random_features = RandomForest(n_estimators=10, max_features=np.sqrt(len(train_df_x[0])))\n",
        "clf_random_features_tree = clf_random_features.fit(train_df_x, train_df_y)\n",
        "y_pred = clf_random_features.predict(val_df_x)\n",
        "print(accuracy_score(val_df_y, y_pred))\n",
        "clf_all_features = RandomForest(n_estimators=10, max_features=len(train_df_x[0]))\n",
        "clf_all_features_tree = clf_all_features.fit(train_df_x, train_df_y)\n",
        "y_pred = clf_all_features.predict(val_df_x)\n",
        "print(accuracy_score(val_df_y, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "part6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def train_your_model(data):\n",
        "    \n",
        "    model = AdaBoost(150, 3)\n",
        "    #print(\"haha\")\n",
        "    train_df_x = np.array(data)[:,0:(len(data[0])-1)]\n",
        "    train_df_y = np.array(data)[:,-1]\n",
        "    #print(\"haha\")\n",
        "    model.fit(train_df_x, train_df_y)\n",
        "    return model\n",
        "# train_df_x = np.array(train_df.values)[:,0:(len(train_df.values[0])-1)]\n",
        "# train_df_y = np.array(train_df.values)[:,-1]\n",
        "my_model = train_your_model(train_df.values)\n",
        "# y_pred = my_model.predict(val_df_x)\n",
        "# val_df_x = np.array(val_df.values)[:,0:(len(val_df.values[0])-1)]\n",
        "# val_df_y = np.array(val_df.values)[:,-1]\n",
        "# print(accuracy_score(val_df_y, y_pred))\n",
        "\n",
        "'''\n",
        "    Some Code to train your \"my_model\"\n",
        "'''\n",
        "\n",
        "x_test = pd.read_csv('x_test.csv')\n",
        "y_pred = my_model.predict(x_test.values)\n",
        "\n",
        "\n",
        "with open('model.pickle', 'wb') as pkl_file:\n",
        "    pickle.dump(my_model, pkl_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "np.save(\"y_pred.npy\", y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQl6-jULdedG"
      },
      "source": [
        "checker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zErpsc0pdfle",
        "outputId": "54d3296c-a75c-4cf8-8fad-c7fb85db8042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** We will check your result for Question 3 manually *** (5 points)\n",
            "*** We will check your result for Question 6 manually *** (20 points)\n",
            "Approximate score range: 45.0 ~ 70.0\n",
            "*** This score is only for reference ***\n"
          ]
        }
      ],
      "source": [
        "# y_test = pd.read_csv('y_test.csv')['price_range'].values\n",
        "# print('Test-set accuarcy score: ', accuracy_score(y_test, y_pred))\n",
        "\n",
        "def discrete_checker(score, thres, clf, name, x_train, y_train, x_test, y_test):\n",
        "    clf.fit(x_train, y_train)\n",
        "    y_pred = clf.predict(x_test)\n",
        "    if accuracy_score(y_test, y_pred) - thres >= 0:\n",
        "        return score\n",
        "    else:\n",
        "        print(f\"{name} failed\")\n",
        "        return 0\n",
        "\n",
        "\n",
        "def patient_checker(score, thres, CLS, kwargs, name,\n",
        "                    x_train, y_train, x_test, y_test, patient=10):\n",
        "    while patient > 0:\n",
        "        patient -= 1\n",
        "        clf = CLS(**kwargs)\n",
        "        clf.fit(x_train, y_train)\n",
        "        y_pred = clf.predict(x_test)\n",
        "        if accuracy_score(y_test, y_pred) - thres >= 0:\n",
        "            return score\n",
        "    print(f\"{name} failed\")\n",
        "    print(\"Considering the randomness, we will check it manually\")\n",
        "    return 0\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "    file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\"\n",
        "    df = pd.read_csv(\n",
        "        file_url,\n",
        "        names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
        "               \"Viscera weight\", \"Shell weight\", \"Age\"]\n",
        "    )\n",
        "\n",
        "    df['Target'] = (df[\"Age\"] > 15).astype(int)\n",
        "    df = df.drop(labels=[\"Age\"], axis=\"columns\")\n",
        "\n",
        "    train_idx = range(0, len(df), 10)\n",
        "    test_idx = range(1, len(df), 20)\n",
        "\n",
        "    train_df = df.iloc[train_idx]\n",
        "    test_df = df.iloc[test_idx]\n",
        "\n",
        "    x_train = train_df.drop(labels=[\"Target\"], axis=\"columns\")\n",
        "    feature_names = x_train.columns.values\n",
        "    x_train = x_train.values\n",
        "    y_train = train_df['Target'].values\n",
        "\n",
        "    x_test = test_df.drop(labels=[\"Target\"], axis=\"columns\")\n",
        "    x_test = x_test.values\n",
        "    y_test = test_df['Target'].values\n",
        "    return x_train, y_train, x_test, y_test, feature_names\n",
        "\n",
        "\n",
        "score = 0\n",
        "\n",
        "data = np.array([1, 2])\n",
        "if abs(gini(data) - 0.5) < 1e-4:\n",
        "    score += 2.5\n",
        "else:\n",
        "    print(\"gini test failed\")\n",
        "\n",
        "if abs(entropy(data) - 1) < 1e-4:\n",
        "    score += 2.5\n",
        "else:\n",
        "    print(\"entropy test failed\")\n",
        "\n",
        "x_train, y_train, x_test, y_test, feature_names = load_dataset()\n",
        "\n",
        "score += discrete_checker(5, 0.9337,\n",
        "                          DecisionTree(criterion='gini', max_depth=3),\n",
        "                          \"DecisionTree(criterion='gini', max_depth=3)\",\n",
        "                          x_train, y_train, x_test, y_test\n",
        "                          )\n",
        "\n",
        "\n",
        "score += discrete_checker(2.5, 0.9036,\n",
        "                          DecisionTree(criterion='gini', max_depth=10),\n",
        "                          \"DecisionTree(criterion='gini', max_depth=10)\",\n",
        "                          x_train, y_train, x_test, y_test\n",
        "                          )\n",
        "\n",
        "score += discrete_checker(2.5, 0.9096,\n",
        "                          DecisionTree(criterion='entropy', max_depth=3),\n",
        "                          \"DecisionTree(criterion='entropy', max_depth=3)\",\n",
        "                          x_train, y_train, x_test, y_test\n",
        "                          )\n",
        "\n",
        "print(\"*** We will check your result for Question 3 manually *** (5 points)\")\n",
        "\n",
        "score += patient_checker(\n",
        "    7.5, 0.91, AdaBoost, {\"n_estimators\": 10},\n",
        "    \"AdaBoost(n_estimators=10)\",\n",
        "    x_train, y_train, x_test, y_test\n",
        ")\n",
        "\n",
        "score += patient_checker(\n",
        "    7.5, 0.87, AdaBoost, {\"n_estimators\": 100},\n",
        "    \"AdaBoost(n_estimators=100)\",\n",
        "    x_train, y_train, x_test, y_test\n",
        ")\n",
        "\n",
        "score += patient_checker(\n",
        "    5, 0.91, RandomForest,\n",
        "    {\"n_estimators\": 10, \"max_features\": np.sqrt(x_train.shape[1])},\n",
        "    \"RandomForest(n_estimators=10, max_features=sqrt(n_features))\",\n",
        "    x_train, y_train, x_test, y_test\n",
        ")\n",
        "\n",
        "score += patient_checker(\n",
        "    5, 0.91, RandomForest,\n",
        "    {\"n_estimators\": 100, \"max_features\": np.sqrt(x_train.shape[1])},\n",
        "    \"RandomForest(n_estimators=100, max_features=sqrt(n_features))\",\n",
        "    x_train, y_train, x_test, y_test\n",
        ")\n",
        "\n",
        "score += patient_checker(\n",
        "    5, 0.92, RandomForest,\n",
        "    {\"n_estimators\": 10, \"max_features\": x_train.shape[1]},\n",
        "    \"RandomForest(n_estimators=10, max_features=n_features)\",\n",
        "    x_train, y_train, x_test, y_test\n",
        ")\n",
        "\n",
        "print(\"*** We will check your result for Question 6 manually *** (20 points)\")\n",
        "print(\"Approximate score range:\", score, \"~\", score + 25)\n",
        "print(\"*** This score is only for reference ***\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "b7377f19eab4b8c2e19b4d5b732c435591579d0f123dd21b146d33dfd161e508"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
